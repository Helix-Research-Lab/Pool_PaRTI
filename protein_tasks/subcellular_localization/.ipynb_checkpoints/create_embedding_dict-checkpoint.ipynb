{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc48bcd5-24a0-4def-bfdd-6fdb8a533703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f7dadc-c4d0-40c6-a125-db5d77224571",
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins_to_load = np.load('proteins_to_load.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afa413a-4ab3-4718-9ca9-8747c0f6c1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling_method = \"cls_pooled\"\n",
    "embedding_dict = {}\n",
    "parent_dir_poolings = \"/oak/stanford/groups/rbaltman/esm_embeddings/esm2_t33_650M_uniprot/post_pooling_seq_vectors\"\n",
    "embedding_dir = os.path.join(parent_dir_poolings, pooling_method)\n",
    "path_dict = f\"dict_embeddings/{pooling_method}.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "371c96e2-69f8-4dde-94aa-59019887f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15879/15879 [03:01<00:00, 87.51it/s] \n"
     ]
    }
   ],
   "source": [
    "for file_index in tqdm(range(len(proteins_to_load))):\n",
    "    acc = proteins_to_load[file_index]\n",
    "    if acc not in proteins_to_load:\n",
    "        continue\n",
    "    file_name  = f\"{acc}.pt\"\n",
    "    if os.path.exists(f\"{embedding_dir}/{file_name}\"):\n",
    "        accession = file_name[:-3]  # Remove file extension\n",
    "        embedding_path = os.path.join(embedding_dir, file_name)\n",
    "        embedding = torch.load(embedding_path)\n",
    "        if not isinstance(embedding, torch.Tensor):\n",
    "            embedding = torch.from_numpy(embedding).to(torch.float32).squeeze()\n",
    "        \n",
    "        #print(\"embedding\", embedding, flush=True)\n",
    "        embedding_dict[accession] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cf63e7f-73ec-45cc-85eb-78cb9a574981",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embedding_dict, path_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d592f6d-72c4-4eb0-800c-3691b9fe9828",
   "metadata": {},
   "source": [
    "## max pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3447e5c9-47cd-4510-b6f2-6166c7389fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15879/15879 [10:23<00:00, 25.46it/s]\n"
     ]
    }
   ],
   "source": [
    "pooling_method = \"max_pooled\"\n",
    "embedding_dict = {}\n",
    "parent_dir_poolings = \"/oak/stanford/groups/rbaltman/esm_embeddings/esm2_t33_650M_uniprot/post_pooling_seq_vectors\"\n",
    "embedding_dir = os.path.join(parent_dir_poolings, pooling_method)\n",
    "path_dict = f\"dict_embeddings/{pooling_method}.pt\"\n",
    "\n",
    "for file_index in tqdm(range(len(proteins_to_load))):\n",
    "    acc = proteins_to_load[file_index]\n",
    "    if acc not in proteins_to_load:\n",
    "        continue\n",
    "    file_name  = f\"{acc}.pt\"\n",
    "    if os.path.exists(f\"{embedding_dir}/{file_name}\"):\n",
    "        accession = file_name[:-3]  # Remove file extension\n",
    "        embedding_path = os.path.join(embedding_dir, file_name)\n",
    "        embedding = torch.load(embedding_path)\n",
    "        if not isinstance(embedding, torch.Tensor):\n",
    "            embedding = torch.from_numpy(embedding).to(torch.float32).squeeze()\n",
    "        \n",
    "        #print(\"embedding\", embedding, flush=True)\n",
    "        embedding_dict[accession] = embedding\n",
    "\n",
    "\n",
    "torch.save(embedding_dict, path_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c368e7b-0831-479a-b0d3-55c5e1446e6b",
   "metadata": {},
   "source": [
    "# mean pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5d9a62d-af22-4570-b832-7469e3631496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15879/15879 [09:37<00:00, 27.48it/s]\n"
     ]
    }
   ],
   "source": [
    "pooling_method = \"mean_pooled\"\n",
    "embedding_dict = {}\n",
    "parent_dir_poolings = \"/oak/stanford/groups/rbaltman/esm_embeddings/esm2_t33_650M_uniprot/post_pooling_seq_vectors\"\n",
    "embedding_dir = os.path.join(parent_dir_poolings, pooling_method)\n",
    "path_dict = f\"dict_embeddings/{pooling_method}.pt\"\n",
    "\n",
    "for file_index in tqdm(range(len(proteins_to_load))):\n",
    "    acc = proteins_to_load[file_index]\n",
    "    if acc not in proteins_to_load:\n",
    "        continue\n",
    "    file_name  = f\"{acc}.pt\"\n",
    "    if os.path.exists(f\"{embedding_dir}/{file_name}\"):\n",
    "        accession = file_name[:-3]  # Remove file extension\n",
    "        embedding_path = os.path.join(embedding_dir, file_name)\n",
    "        embedding = torch.load(embedding_path)\n",
    "        if not isinstance(embedding, torch.Tensor):\n",
    "            embedding = torch.from_numpy(embedding).to(torch.float32).squeeze()\n",
    "        \n",
    "        #print(\"embedding\", embedding, flush=True)\n",
    "        embedding_dict[accession] = embedding\n",
    "\n",
    "\n",
    "torch.save(embedding_dict, path_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5718ab22-0734-4250-935b-7820ba71a7e1",
   "metadata": {},
   "source": [
    "# Pool PaRTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58150114-4a9f-4dc2-b3a3-b2c57534b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15879/15879 [09:18<00:00, 28.42it/s]\n"
     ]
    }
   ],
   "source": [
    "pooling_method = \"PR_contact_prune_topk_no_enh\"\n",
    "embedding_dict = {}\n",
    "parent_dir_poolings = \"/oak/stanford/groups/rbaltman/esm_embeddings/esm2_t33_650M_uniprot/post_pooling_seq_vectors\"\n",
    "embedding_dir = os.path.join(parent_dir_poolings, pooling_method)\n",
    "path_dict = f\"dict_embeddings/{pooling_method}.pt\"\n",
    "\n",
    "for file_index in tqdm(range(len(proteins_to_load))):\n",
    "    acc = proteins_to_load[file_index]\n",
    "    if acc not in proteins_to_load:\n",
    "        continue\n",
    "    file_name  = f\"{acc}.pt\"\n",
    "    if os.path.exists(f\"{embedding_dir}/{file_name}\"):\n",
    "        accession = file_name[:-3]  # Remove file extension\n",
    "        embedding_path = os.path.join(embedding_dir, file_name)\n",
    "        embedding = torch.load(embedding_path)\n",
    "        if not isinstance(embedding, torch.Tensor):\n",
    "            embedding = torch.from_numpy(embedding).to(torch.float32).squeeze()\n",
    "        \n",
    "        #print(\"embedding\", embedding, flush=True)\n",
    "        embedding_dict[accession] = embedding\n",
    "\n",
    "\n",
    "torch.save(embedding_dict, path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e84f761-d6d1-450f-87f9-8bf53cec73b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0710, -0.0341,  0.0738,  ..., -0.3235,  0.2001,  0.0547])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"dict_embeddings/cls_pooled.pt\")['Q7L5N1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c312bc7c-e48c-4d3d-814d-5ca037bc715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5824, 0.4923, 0.4563,  ..., 0.2624, 0.5301, 0.7738])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"dict_embeddings/max_pooled.pt\")['Q7L5N1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6df4d4-73d3-47f4-a0ac-78b405b8ac1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0026, -0.0982, -0.0214,  ..., -0.2482, -0.0141,  0.1950])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"dict_embeddings/mean_pooled.pt\")['Q7L5N1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae72e8de-7136-49ef-baa2-431fd2fe942c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0016, -0.0949, -0.0191,  ..., -0.2570, -0.0132,  0.1928],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"dict_embeddings/PR_contact_prune_topk_no_enh.pt\")['Q7L5N1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5329ca85-8b5c-4db8-9621-e58c77e1e27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
